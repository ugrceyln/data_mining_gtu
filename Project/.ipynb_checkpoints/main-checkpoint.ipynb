{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle\n",
    "import scipy.misc\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# import data visualization packages\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pickle\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')\n",
    "# import data preparing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy.random as rng\n",
    "import random\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(630)\n",
    "\n",
    "\n",
    "import os, sys\n",
    "import math\n",
    "from math import sqrt\n",
    "import itertools\n",
    "from errno import EEXIST\n",
    "from os import makedirs,path\n",
    "import logging as logger\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_test_data_from_file(file_name):\n",
    "\n",
    "    df_raw = pd.read_csv(str.format('{0}/{1}', _path_, file_name), sep=' ', header=None)\n",
    "    df_raw.drop([26, 27], axis=1, inplace=True)\n",
    "\n",
    "    col_names = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8',\n",
    "                 's9', 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    df_raw.columns = col_names\n",
    "\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_data_from_file(file_name):\n",
    "\n",
    "    df_raw = pd.read_csv(str.format('{0}/{1}', _path_, file_name), sep=' ', header=None)\n",
    "\n",
    "    df_raw.drop([1], axis=1, inplace=True)\n",
    "    df_raw.columns = [label_reg]\n",
    "\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(df_in, period):\n",
    "\n",
    "    # make a dataframe to hold the last cycle for each enginge in the dataset\n",
    "    df_max_cycle = pd.DataFrame(df_in.groupby('id')['cycle'].max())\n",
    "    df_max_cycle.reset_index(level=0, inplace=True)\n",
    "    df_max_cycle.columns = ['id', 'last_cycle']\n",
    "\n",
    "    # add time-to-failure RUL as a new column - regression label\n",
    "    df_in = pd.merge(df_in, df_max_cycle, on='id')\n",
    "    df_in[label_reg] = df_in['last_cycle'] - df_in['cycle']\n",
    "    df_in.drop(['last_cycle'], axis=1, inplace=True)\n",
    "\n",
    "    # create binary classification label\n",
    "    df_in[label_binc] = df_in[label_reg].apply(lambda x: 1 if x <= period else 0)\n",
    "\n",
    "    # create multi-class classification label\n",
    "    df_in[label_mcc] = df_in[label_reg].apply(lambda x: 2 if x <= period / 2 else 1 if x <= period else 0)\n",
    "\n",
    "    return df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(df_test_in, df_truth_in, period):\n",
    "\n",
    "    df_tst_last_cycle = pd.DataFrame(df_test_in.groupby('id')['cycle'].max())\n",
    "\n",
    "    df_tst_last_cycle.reset_index(level=0, inplace=True)\n",
    "    df_tst_last_cycle.columns = ['id', 'last_cycle']\n",
    "\n",
    "    df_test_in = pd.merge(df_test_in, df_tst_last_cycle, on='id')\n",
    "\n",
    "    df_test_in = df_test_in[df_test_in['cycle'] == df_test_in['last_cycle']]\n",
    "\n",
    "    df_test_in.drop(['last_cycle'], axis=1, inplace=True)\n",
    "\n",
    "    df_test_in.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_test_in = pd.concat([df_test_in, df_truth_in], axis=1)\n",
    "\n",
    "    # create binary classification label\n",
    "    df_test_in[label_binc] = df_test_in[label_reg].apply(lambda x: 1 if x <= period else 0)\n",
    "\n",
    "    # create multi-class classification label\n",
    "    df_test_in[label_mcc] = df_test_in[label_reg].apply(lambda x: 2 if x <= period / 2 else 1 if x <= period else 0)\n",
    "\n",
    "    return df_test_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_test_data(df_test_in, df_truth_in, period):\n",
    "\n",
    "    df_tst_last_cycle = pd.DataFrame(df_test_in.groupby('id')['cycle'].max())\n",
    "\n",
    "    df_tst_last_cycle.reset_index(level=0, inplace=True)\n",
    "    df_tst_last_cycle.columns = ['id', 'last_cycle']\n",
    "\n",
    "    df_tst_last_cycle['last_cycle'] = df_tst_last_cycle['last_cycle'].add(df_truth_in[label_reg])\n",
    "\n",
    "    df_test_in = pd.merge(df_test_in, df_tst_last_cycle, on='id')\n",
    "\n",
    "    df_test_in[label_reg] = df_test_in['last_cycle'] - df_test_in['cycle']\n",
    "    df_test_in.drop(['last_cycle'], axis=1, inplace=True)\n",
    "\n",
    "    df_test_in.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # create binary classification label\n",
    "    df_test_in[label_binc] = df_test_in[label_reg].apply(lambda x: 1 if x <= period else 0)\n",
    "\n",
    "    # create multi-class classification label\n",
    "    df_test_in[label_mcc] = df_test_in[label_reg].apply(lambda x: 2 if x <= period / 2 else 1 if x <= period else 0)\n",
    "\n",
    "    return df_test_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_path_ = 'turbofan datasets/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_reg = 'RUL'\n",
    "label_binc = 'BINC'\n",
    "label_mcc = 'MCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_number = 1\n",
    "categoric_features = ['id']\n",
    "numeric_features = ['setting1', 'setting2', 'setting3',\n",
    "                    's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
    "                    's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21' ]\n",
    "    \n",
    "test_data_types = ['online', 'batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "df_train_raw = read_train_test_data_from_file(file_name='train_FD00{0}.txt'.format(data_set_number))\n",
    "df_test_raw = read_train_test_data_from_file(file_name='test_FD00{0}.txt'.format(data_set_number))\n",
    "df_truth = read_label_data_from_file(file_name='RUL_FD00{0}.txt'.format(data_set_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5     s6      s7       s8       s9  s10    s11     s12      s13  \\\n",
       "0  14.62  21.61  554.36  2388.06  9046.19  1.3  47.47  521.66  2388.02   \n",
       "1  14.62  21.61  553.75  2388.04  9044.07  1.3  47.49  522.28  2388.07   \n",
       "2  14.62  21.61  554.26  2388.08  9052.94  1.3  47.27  522.42  2388.03   \n",
       "3  14.62  21.61  554.45  2388.11  9049.48  1.3  47.13  522.86  2388.08   \n",
       "4  14.62  21.61  554.00  2388.06  9055.15  1.3  47.28  522.19  2388.04   \n",
       "\n",
       "       s14     s15   s16  s17   s18    s19    s20      s21  \n",
       "0  8138.62  8.4195  0.03  392  2388  100.0  39.06  23.4190  \n",
       "1  8131.49  8.4318  0.03  392  2388  100.0  39.00  23.4236  \n",
       "2  8133.23  8.4178  0.03  390  2388  100.0  38.95  23.3442  \n",
       "3  8133.83  8.3682  0.03  392  2388  100.0  38.88  23.3739  \n",
       "4  8133.80  8.4294  0.03  393  2388  100.0  38.90  23.4044  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels to training data using period of 30 cycles for classification\n",
    "df_train = prepare_train_data(df_in=df_train_raw, period=30)\n",
    "# save the training data to csv file for later use\n",
    "df_train.to_csv('{0}/train{1}.csv'.format(_path_, data_set_number), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>BINC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.43</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>9065.52</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.07</td>\n",
       "      <td>519.49</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.86</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>9065.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.04</td>\n",
       "      <td>519.68</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.94</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>9065.90</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.09</td>\n",
       "      <td>520.01</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.68</td>\n",
       "      <td>2388.25</td>\n",
       "      <td>9073.72</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.39</td>\n",
       "      <td>519.67</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.79</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>9061.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.20</td>\n",
       "      <td>519.30</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "20626  100    196   -0.0004   -0.0003     100.0  518.67  643.49  1597.98   \n",
       "20627  100    197   -0.0016   -0.0005     100.0  518.67  643.54  1604.50   \n",
       "20628  100    198    0.0004    0.0000     100.0  518.67  643.42  1602.46   \n",
       "20629  100    199   -0.0011    0.0003     100.0  518.67  643.23  1605.26   \n",
       "20630  100    200   -0.0032   -0.0005     100.0  518.67  643.85  1600.38   \n",
       "\n",
       "            s4     s5     s6      s7       s8       s9  s10    s11     s12  \\\n",
       "20626  1428.63  14.62  21.61  551.43  2388.19  9065.52  1.3  48.07  519.49   \n",
       "20627  1433.58  14.62  21.61  550.86  2388.23  9065.11  1.3  48.04  519.68   \n",
       "20628  1428.18  14.62  21.61  550.94  2388.24  9065.90  1.3  48.09  520.01   \n",
       "20629  1426.53  14.62  21.61  550.68  2388.25  9073.72  1.3  48.39  519.67   \n",
       "20630  1432.14  14.62  21.61  550.79  2388.26  9061.48  1.3  48.20  519.30   \n",
       "\n",
       "           s13      s14     s15   s16  s17   s18    s19    s20      s21  RUL  \\\n",
       "20626  2388.26  8137.60  8.4956  0.03  397  2388  100.0  38.49  22.9735    4   \n",
       "20627  2388.22  8136.50  8.5139  0.03  395  2388  100.0  38.30  23.1594    3   \n",
       "20628  2388.24  8141.05  8.5646  0.03  398  2388  100.0  38.44  22.9333    2   \n",
       "20629  2388.23  8139.29  8.5389  0.03  395  2388  100.0  38.29  23.0640    1   \n",
       "20630  2388.26  8137.33  8.5036  0.03  396  2388  100.0  38.37  23.0522    0   \n",
       "\n",
       "       BINC  MCC  \n",
       "20626     1    2  \n",
       "20627     1    2  \n",
       "20628     1    2  \n",
       "20629     1    2  \n",
       "20630     1    2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels to test data using period of 30 cycles for classification\n",
    "df_test = prepare_all_test_data(df_test_in=df_test_raw, df_truth_in=df_truth, period=30)\n",
    "# save the test data to csv file for later use\n",
    "df_test.to_csv('{0}/test{1}.csv'.format(_path_, data_set_number), index=False)\n",
    "\n",
    "df_test = prepare_test_data(df_test_in=df_test_raw, df_truth_in=df_truth, period=30)   # get for last-max- line\n",
    "# save the test data to csv file for later use\n",
    "df_test.to_csv('{0}/_test_{1}.csv'.format(_path_, data_set_number), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>s11</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>BINC</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>97</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.30</td>\n",
       "      <td>1590.88</td>\n",
       "      <td>1397.94</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.99</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>9062.41</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.14</td>\n",
       "      <td>522.30</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>8148.24</td>\n",
       "      <td>8.4110</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.96</td>\n",
       "      <td>23.4606</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>134</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>-0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.59</td>\n",
       "      <td>1582.96</td>\n",
       "      <td>1410.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.05</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9076.36</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.38</td>\n",
       "      <td>521.58</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8155.48</td>\n",
       "      <td>8.4500</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.61</td>\n",
       "      <td>23.2953</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.68</td>\n",
       "      <td>1599.51</td>\n",
       "      <td>1415.47</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.44</td>\n",
       "      <td>2388.13</td>\n",
       "      <td>9062.34</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.66</td>\n",
       "      <td>521.53</td>\n",
       "      <td>2388.09</td>\n",
       "      <td>8146.39</td>\n",
       "      <td>8.4235</td>\n",
       "      <td>0.03</td>\n",
       "      <td>394</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.76</td>\n",
       "      <td>23.3608</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>97</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.00</td>\n",
       "      <td>1585.03</td>\n",
       "      <td>1397.98</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.75</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>9067.16</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.26</td>\n",
       "      <td>521.82</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8150.38</td>\n",
       "      <td>8.4003</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3595</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.95</td>\n",
       "      <td>1601.62</td>\n",
       "      <td>1424.99</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>552.48</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9155.03</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.80</td>\n",
       "      <td>521.07</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8214.64</td>\n",
       "      <td>8.4903</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.70</td>\n",
       "      <td>23.1855</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  cycle  setting1  setting2  setting3      s1      s2       s3  \\\n",
       "95   96     97   -0.0006    0.0003     100.0  518.67  642.30  1590.88   \n",
       "96   97    134    0.0013   -0.0001     100.0  518.67  642.59  1582.96   \n",
       "97   98    121    0.0017    0.0001     100.0  518.67  642.68  1599.51   \n",
       "98   99     97    0.0047   -0.0000     100.0  518.67  642.00  1585.03   \n",
       "99  100    198    0.0013    0.0003     100.0  518.67  642.95  1601.62   \n",
       "\n",
       "         s4     s5     s6      s7       s8       s9  s10    s11     s12  \\\n",
       "95  1397.94  14.62  21.61  553.99  2388.03  9062.41  1.3  47.14  522.30   \n",
       "96  1410.92  14.62  21.61  554.05  2388.06  9076.36  1.3  47.38  521.58   \n",
       "97  1415.47  14.62  21.61  553.44  2388.13  9062.34  1.3  47.66  521.53   \n",
       "98  1397.98  14.62  21.61  554.75  2388.01  9067.16  1.3  47.26  521.82   \n",
       "99  1424.99  14.62  21.61  552.48  2388.06  9155.03  1.3  47.80  521.07   \n",
       "\n",
       "        s13      s14     s15   s16  s17   s18    s19    s20      s21  RUL  \\\n",
       "95  2388.01  8148.24  8.4110  0.03  391  2388  100.0  38.96  23.4606  137   \n",
       "96  2388.06  8155.48  8.4500  0.03  395  2388  100.0  38.61  23.2953   82   \n",
       "97  2388.09  8146.39  8.4235  0.03  394  2388  100.0  38.76  23.3608   59   \n",
       "98  2388.02  8150.38  8.4003  0.03  391  2388  100.0  38.95  23.3595  117   \n",
       "99  2388.05  8214.64  8.4903  0.03  396  2388  100.0  38.70  23.1855   20   \n",
       "\n",
       "    BINC  MCC  \n",
       "95     0    0  \n",
       "96     0    0  \n",
       "97     0    0  \n",
       "98     0    0  \n",
       "99     1    1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccaca4bbaec34451836ab724ab0ab782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tab(children=(HTML(value='<div id=\"overview-content\" class=\"row variable spacing\">\\n    <div class=\"row\">\\n   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Report generated with <a href=\"https://github.com/pandas-profiling/pandas-profiling\">pandas-profiling</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "pandas_profiling.ProfileReport(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_features(data):\n",
    "\n",
    "    features = [ \n",
    "        'setting1', 'setting2', 'setting3',\n",
    "        's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
    "        's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21'\n",
    "    ]\n",
    "\n",
    "    engine_num = 10\n",
    "\n",
    "    \"\"\"Plot 4 main graphs for a single feature.\n",
    "\n",
    "        plot1: histogram\n",
    "        plot2: boxplot\n",
    "        plot3: line plot (time series over cycle)\n",
    "        plot4: scatter plot vs. regression label RUL\n",
    "\n",
    "    Args:\n",
    "        feature (str): The column name of the feature to be plotted.\n",
    "        engine_num (int): The number of random engines to be plotted for plot 3. \n",
    "        Range from 1 -100, 0:all engines, >100: all engines.\n",
    "\n",
    "    Returns:\n",
    "        plots\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for feature in features:\n",
    "\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "        sub1 = fig.add_subplot(221)\n",
    "        sub1.set_title(feature + ' histogram')\n",
    "        sub1.hist(data[feature])\n",
    "\n",
    "        sub2 = fig.add_subplot(222)\n",
    "        sub2.set_title(feature + ' boxplot')\n",
    "        sub2.boxplot(data[feature])\n",
    "\n",
    "        # np.random.seed(12345)\n",
    "\n",
    "        if engine_num > 100 or engine_num <= 0:\n",
    "            select_engines = list(pd.unique(data.id))\n",
    "        else:\n",
    "            select_engines = np.random.choice(range(1, 101), engine_num, replace=False)\n",
    "\n",
    "        sub3 = fig.add_subplot(223)\n",
    "        sub3.set_title('time series: ' + feature + ' / cycle')\n",
    "        sub3.set_xlabel('cycle')\n",
    "        for i in select_engines:\n",
    "            df = data[['cycle', feature]][data.id == i]\n",
    "            sub3.plot(df['cycle'], df[feature], label='engine ' + str(i))\n",
    "            sub3.legend(loc=\"upper right\")\n",
    "\n",
    "        sub4 = fig.add_subplot(224)\n",
    "        sub4.set_title(\"scatter: \" + feature + \" / RUL (regr label)\")\n",
    "        sub4.set_xlabel(label_reg)\n",
    "        sub4.scatter(data[label_reg], data[feature])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(str.format('turbofan datasets/data_visualization/plot_hist_etc/{}', feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr_lbl = pd.read_csv('{0}/train{1}.csv'.format(_path_, data_set_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_features(data=df_tr_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(data):\n",
    "\n",
    "    features = ['setting1', 'setting2', 'setting3', \n",
    "                's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
    "                's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    engine_num = 10\n",
    "\n",
    "    \"\"\"Plot time series of a single sensor for 10 random sample engines.\n",
    "\n",
    "        Args:\n",
    "        s (str): The column name of the sensor to be plotted.\n",
    "\n",
    "    Returns:\n",
    "        plots\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for feature in features:\n",
    "\n",
    "        fig, axes = plt.subplots(engine_num, 1, sharex=True, figsize=(25, 15))\n",
    "        fig.suptitle(feature + ' time series / cycle', fontsize=15)\n",
    "\n",
    "        # np.random.seed(12345)\n",
    "        select_engines = np.random.choice(range(1, 101), engine_num, replace=False).tolist()\n",
    "\n",
    "        for e_id in select_engines:\n",
    "            df = data[['cycle', feature]][data.id == e_id]\n",
    "            i = select_engines.index(e_id)\n",
    "            axes[i].plot(df['cycle'], df[feature], color='lime')\n",
    "            axes[i].set_ylabel('engine ' + str(e_id))\n",
    "            axes[i].set_xlabel('cycle')\n",
    "            axes[i].set_title('engine ' + str(e_id), loc='right')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.savefig(str.format('turbofan datasets/data_visualization/time_series/{}', feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(data=df_tr_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation_with_pandas_lib(data):\n",
    "\n",
    "    # # plot and compare the standard deviation of input features:\n",
    "    # data[features].std().plot(kind='bar', figsize=(8, 6), title=\"Features Standard Deviation\")\n",
    "    #\n",
    "    # # plot and compare the log standard deviation of input features:\n",
    "    # data[features].std().plot(kind='bar', figsize=(8, 6), logy=True, title=\"Features Standard Deviation (log)\")\n",
    "\n",
    "    features = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11',\n",
    "                's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
    "\n",
    "    # get ordered list features correlation with regression label RUL\n",
    "    corr_data = data[features].corrwith(data.RUL).sort_values(ascending=False).dropna()\n",
    "\n",
    "    # get correlation features names\n",
    "    correl_features = list(corr_data.index.values)\n",
    "\n",
    "    correl_features_lbl = correl_features + [label_reg]\n",
    "\n",
    "    corr_matrix = np.corrcoef(data[correl_features_lbl].values.T)\n",
    "\n",
    "    sns.set(font_scale=1.0)\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    hm = sns.heatmap(corr_matrix, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 8},\n",
    "                     yticklabels=correl_features_lbl, xticklabels=correl_features_lbl)\n",
    "    plt.title('Features Correlation Heatmap')\n",
    "    plt.savefig('turbofan datasets/data_visualization/features_correlation_heatmap')\n",
    "    plt.clf()\n",
    "\n",
    "    # reset matplotlib original theme\n",
    "    sns.reset_orig()\n",
    "\n",
    "    # create scatter matrix to disply relatiohships and distribution among features and regression label\n",
    "    scatter_matrix(data[correl_features_lbl], alpha=0.2, figsize=(20, 20), diagonal='kde')  # diagonal='hist'\n",
    "    plt.savefig('turbofan datasets/data_visualization/scatter_matrix')\n",
    "    plt.clf()\n",
    "\n",
    "    '''\n",
    "\n",
    "        Most of the features have normal distribution which has positive effect on machine learning algorithms. \n",
    "        Most of the features have non-linear relationship with the regression label RUL, \n",
    "        so using polynomial models may lead to better results\n",
    "\n",
    "        There is a very high correlation (> 0.8) between some features e.g.(s14 & s9), (s11 & s4), \n",
    "        (s11 & s7), (s11 & s12), (s4 & s12), (s8 & s13), (s7 & s12). \n",
    "        This multicollinearity may hurt the performance of some machine learning algorithms. \n",
    "        So, part of these features will be target for elimination \n",
    "        in feature selection during the modeling phase.  \n",
    "        Most features have nonlinear relation with the RUL, hence adding their polynomial transforms \n",
    "        may enhance models performance.\n",
    "        Most features exhibit normal distribution which is likely improves models performance.\n",
    "        AUC ROC should be used for classification models evaluation instead of Accuracy due to \n",
    "        class’s imbalance in the training data.\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_correlation_with_pandas_lib(data=df_tr_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat_for_classification_labels(data):\n",
    "\n",
    "    # BINC\n",
    "    df_bin_analysis = data[[label_binc]]\n",
    "\n",
    "    df_bin_analysis['freq'] = df_bin_analysis.groupby(label_binc)[label_binc].transform('count')\n",
    "    df_bin_analysis.drop_duplicates(keep='first', inplace=True)\n",
    "    df_bin_analysis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    total = np.sum(df_bin_analysis.ix[:, 'freq':].values)\n",
    "    df_bin_analysis['percent'] = df_bin_analysis.ix[:, 'freq':].sum(axis=1) / total * 100\n",
    "\n",
    "    writer = pd.ExcelWriter('turbofan datasets/data_visualization/bin_statistics.xlsx')\n",
    "    df_bin_analysis.to_excel(writer, 'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "    # MCC\n",
    "    df_mcc_analysis = data[[label_mcc]]\n",
    "\n",
    "    df_mcc_analysis['freq'] = df_mcc_analysis.groupby(label_mcc)[label_mcc].transform('count')\n",
    "    df_mcc_analysis.drop_duplicates(keep='first', inplace=True)\n",
    "    df_mcc_analysis.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    total = np.sum(df_mcc_analysis.ix[:, 'freq':].values)\n",
    "    df_mcc_analysis['percent'] = df_mcc_analysis.ix[:, 'freq':].sum(axis=1) / total * 100\n",
    "\n",
    "    writer = pd.ExcelWriter('turbofan datasets/data_visualization/mcc_statistics.xlsx')\n",
    "    df_mcc_analysis.to_excel(writer, 'Sheet1', index=False)\n",
    "    writer.save()\n",
    "\n",
    "    print(\"\\nRecord #/% for each class-binaryclassification- :\\n\", data[label_binc].value_counts())\n",
    "    print('\\nNegative samples =  {0:.0%}'.format(\n",
    "        data[label_binc].value_counts()[0] / data[label_binc].count()))\n",
    "    print('\\nPositive samples =  {0:.0%}'.format(\n",
    "        data[label_binc].value_counts()[1] / data[label_binc].count()))\n",
    "\n",
    "    # print stat for multiclass classification label\n",
    "    print(\"\\n\\nRecord #/% for each class-multiclassification- :\\n\", data[label_mcc].value_counts())\n",
    "    print('\\nClass 0 samples =  {0:.0%}'.format(\n",
    "        data[label_mcc].value_counts()[0] / data[label_mcc].count()))\n",
    "    print('\\nClass 1 samples =  {0:.0%}'.format(\n",
    "        data[label_mcc].value_counts()[1] / data[label_mcc].count()))\n",
    "    print('\\nClass 2 samples =  {0:.0%}'.format(\n",
    "        data[label_mcc].value_counts()[2] / data[label_mcc].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record #/% for each class-binaryclassification- :\n",
      " 0    17531\n",
      "1     3100\n",
      "Name: BINC, dtype: int64\n",
      "\n",
      "Negative samples =  85%\n",
      "\n",
      "Positive samples =  15%\n",
      "\n",
      "\n",
      "Record #/% for each class-multiclassification- :\n",
      " 0    17531\n",
      "2     1600\n",
      "1     1500\n",
      "Name: MCC, dtype: int64\n",
      "\n",
      "Class 0 samples =  85%\n",
      "\n",
      "Class 1 samples =  7%\n",
      "\n",
      "Class 2 samples =  8%\n"
     ]
    }
   ],
   "source": [
    "print_stat_for_classification_labels(data=df_tr_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts_lbl = pd.read_csv('{0}/test{1}.csv'.format(_path_, data_set_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_columns = ['s1', 's5', 's10', 's16', 's18', 's19', 'setting3']\n",
    "train_data = df_tr_lbl.drop(removed_columns, axis=1)\n",
    "test_data = df_ts_lbl.drop(removed_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20631, 22), (13096, 22))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(set(train_data.columns).difference(['BINC', 'MCC', 'RUL', 'id', 'cycle']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINC CLASSIFICATION\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, fbeta_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['BINC']\n",
    "X_train = train_data[feature_names]\n",
    "\n",
    "y_test = test_data['BINC']\n",
    "X_test = test_data[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s21</th>\n",
       "      <th>s17</th>\n",
       "      <th>setting2</th>\n",
       "      <th>s11</th>\n",
       "      <th>s7</th>\n",
       "      <th>s20</th>\n",
       "      <th>s2</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s12</th>\n",
       "      <th>s6</th>\n",
       "      <th>s3</th>\n",
       "      <th>s9</th>\n",
       "      <th>s8</th>\n",
       "      <th>s4</th>\n",
       "      <th>s13</th>\n",
       "      <th>setting1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.4190</td>\n",
       "      <td>392</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>47.47</td>\n",
       "      <td>554.36</td>\n",
       "      <td>39.06</td>\n",
       "      <td>641.82</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>521.66</td>\n",
       "      <td>21.61</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>-0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.4236</td>\n",
       "      <td>392</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>47.49</td>\n",
       "      <td>553.75</td>\n",
       "      <td>39.00</td>\n",
       "      <td>642.15</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>522.28</td>\n",
       "      <td>21.61</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.3442</td>\n",
       "      <td>390</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>47.27</td>\n",
       "      <td>554.26</td>\n",
       "      <td>38.95</td>\n",
       "      <td>642.35</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>522.42</td>\n",
       "      <td>21.61</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>-0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.3739</td>\n",
       "      <td>392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>47.13</td>\n",
       "      <td>554.45</td>\n",
       "      <td>38.88</td>\n",
       "      <td>642.35</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>522.86</td>\n",
       "      <td>21.61</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.4044</td>\n",
       "      <td>393</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>47.28</td>\n",
       "      <td>554.00</td>\n",
       "      <td>38.90</td>\n",
       "      <td>642.37</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>522.19</td>\n",
       "      <td>21.61</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>-0.0019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s21  s17  setting2    s11      s7    s20      s2      s14     s15  \\\n",
       "0  23.4190  392   -0.0004  47.47  554.36  39.06  641.82  8138.62  8.4195   \n",
       "1  23.4236  392   -0.0003  47.49  553.75  39.00  642.15  8131.49  8.4318   \n",
       "2  23.3442  390    0.0003  47.27  554.26  38.95  642.35  8133.23  8.4178   \n",
       "3  23.3739  392    0.0000  47.13  554.45  38.88  642.35  8133.83  8.3682   \n",
       "4  23.4044  393   -0.0002  47.28  554.00  38.90  642.37  8133.80  8.4294   \n",
       "\n",
       "      s12     s6       s3       s9       s8       s4      s13  setting1  \n",
       "0  521.66  21.61  1589.70  9046.19  2388.06  1400.60  2388.02   -0.0007  \n",
       "1  522.28  21.61  1591.82  9044.07  2388.04  1403.14  2388.07    0.0019  \n",
       "2  522.42  21.61  1587.99  9052.94  2388.08  1404.20  2388.03   -0.0043  \n",
       "3  522.86  21.61  1582.79  9049.48  2388.11  1401.87  2388.08    0.0007  \n",
       "4  522.19  21.61  1582.85  9055.15  2388.06  1406.22  2388.04   -0.0019  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, title='', path='results/binc/'):\n",
    "    \n",
    "    # Plot confusion matrix in a beautiful manner\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(conf_matrix, annot=True, ax = ax, fmt = 'g'); #annot=True to annotate cells\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted', fontsize=20)\n",
    "    ax.xaxis.set_label_position('top') \n",
    "    ax.xaxis.set_ticklabels(['health', 'failure'], fontsize = 15)\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    ax.set_ylabel('Actual', fontsize=20)\n",
    "    ax.yaxis.set_ticklabels(['health', 'failure'], fontsize = 15)\n",
    "    plt.savefig(path + title)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LogisticRegression_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LogisticRegression(random_state=42, verbose=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DecisionTree_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RandomForest_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GradientBoosting_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = GradientBoostingClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BaggingClassifier_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = BaggingClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GaussianNB_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred) \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SVMClassifier_algorithm(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred) \n",
    "    f1_score_ = f1_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)   \n",
    "    \n",
    "    return score, conf_matrix, f1_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy is:  0.9846518020769701\n",
      "LogisticRegression f1 score:  0.6479859894921192\n"
     ]
    }
   ],
   "source": [
    "log_score, log_conf_matrix, log_f1_score = run_LogisticRegression_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(log_conf_matrix, title='LogisticRegression')\n",
    "print('LogisticRegression accuracy is: ', log_score)  \n",
    "print('LogisticRegression f1 score: ', log_f1_score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree accuracy is:  0.976634086744044\n",
      "DecisionTree f1 score:  0.5513196480938416\n"
     ]
    }
   ],
   "source": [
    "dt_score, dt_conf_matrix, dt_f1_score = run_DecisionTree_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(dt_conf_matrix, title='DecisionTree')\n",
    "print('DecisionTree accuracy is: ', dt_score) \n",
    "print('DecisionTree f1 score: ', dt_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest accuracy is:  0.9865607819181429\n",
      "RandomForest f1 score:  0.6955017301038062\n"
     ]
    }
   ],
   "source": [
    "rf_score, rf_conf_matrix, rf_f1_score = run_RandomForest_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(rf_conf_matrix, title='RandomForest')\n",
    "print('RandomForest accuracy is: ', rf_score) \n",
    "print('RandomForest f1 score: ', rf_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting accuracy is:  0.9870189370800244\n",
      "GradientBoosting f1 score:  0.7128378378378377\n"
     ]
    }
   ],
   "source": [
    "gb_score, gb_conf_matrix, gb_f1_score = run_GradientBoosting_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(gb_conf_matrix, title='GradientBoosting')\n",
    "print('GradientBoosting accuracy is: ', gb_score) \n",
    "print('GradientBoosting f1 score: ', gb_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier accuracy is:  0.9853390348197923\n",
      "BaggingClassifier f1 score:  0.6595744680851063\n"
     ]
    }
   ],
   "source": [
    "bc_score, bc_conf_matrix, bc_f1_score = run_BaggingClassifier_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(bc_conf_matrix, title='BaggingClassifier')\n",
    "print('BaggingClassifier accuracy is: ', bc_score)\n",
    "print('BaggingClassifier f1 score: ', bc_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB accuracy is:  0.9741142333536957\n",
      "GaussianNB f1 score:  0.6327193932827736\n"
     ]
    }
   ],
   "source": [
    "nb_score, nb_conf_matrix, nb_f1_score = run_GaussianNB_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(nb_conf_matrix, title='GaussianNB')\n",
    "print('GaussianNB accuracy is: ', nb_score)\n",
    "print('GaussianNB f1 score: ', nb_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVMClassifier accuracy is:  0.9849572388515577\n",
      "SVMClassifier f1 score:  0.6475849731663686\n"
     ]
    }
   ],
   "source": [
    "svm_score, svm_conf_matrix, svm_f1_score = run_SVMClassifier_algorithm(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(nb_conf_matrix, title='SVMClassifier')\n",
    "print('SVMClassifier accuracy is: ', svm_score)\n",
    "print('SVMClassifier f1 score: ', svm_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-class CLASSIFICATION\n",
    "\n",
    "y_train = train_data['MCC']\n",
    "X_train = train_data[feature_names]\n",
    "\n",
    "y_test = test_data['MCC']\n",
    "X_test = test_data[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LogisticRegression_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LogisticRegression(random_state=42, verbose=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)  \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_DecisionTree_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = DecisionTreeClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred) \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RandomForest_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GradientBoosting_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = GradientBoostingClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_BaggingClassifier_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = BaggingClassifier(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_GaussianNB_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SVMClassifier_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)  \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred) \n",
    "    f1_score_macro = f1_score(y_test, y_pred, average='macro') \n",
    "    f1_score_micro = f1_score(y_test, y_pred, average='micro')    \n",
    "    \n",
    "    return score, conf_matrix, f1_score_macro, f1_score_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_ f1 score-macro-:  0.6028655633748056\n",
      "LogisticRegression_ f1 score-micro-:  0.9793830177153329\n"
     ]
    }
   ],
   "source": [
    "log_score, log_conf_matrix, log_f1_score_macro, log_f1_score_micro = run_LogisticRegression_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(log_conf_matrix, title='LogisticRegression_')\n",
    "print('LogisticRegression_ f1 score-macro-: ', log_f1_score_macro)\n",
    "print('LogisticRegression_ f1 score-micro-: ', log_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree_ f1 score-macro-:  0.6304340755867722\n",
      "DecisionTree_ f1 score-micro-:  0.974801466096518\n"
     ]
    }
   ],
   "source": [
    "dt_score, dt_conf_matrix, dt_f1_score_macro, dt_f1_score_micro = run_DecisionTree_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(dt_conf_matrix, title='DecisionTree_')\n",
    "print('DecisionTree_ f1 score-macro-: ', dt_f1_score_macro)\n",
    "print('DecisionTree_ f1 score-micro-: ', dt_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest_ f1 score-macro-:  0.7153792200690358\n",
      "RandomForest_ f1 score-micro-:  0.9835064141722664\n"
     ]
    }
   ],
   "source": [
    "rf_score, rf_conf_matrix, rf_f1_score_macro, rf_f1_score_micro = run_RandomForest_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(rf_conf_matrix, title='RandomForest_')\n",
    "print('RandomForest_ f1 score-macro-: ', rf_f1_score_macro)\n",
    "print('RandomForest_ f1 score-micro-: ', rf_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoosting_ f1 score-macro-:  0.7227036514272202\n",
      "GradientBoosting_ f1 score-micro-:  0.9835064141722664\n"
     ]
    }
   ],
   "source": [
    "gb_score, gb_conf_matrix, gb_f1_score_macro,gb_f1_score_micro = run_GradientBoosting_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(gb_conf_matrix, title='GradientBoosting_')\n",
    "print('GradientBoosting_ f1 score-macro-: ', gb_f1_score_macro)\n",
    "print('GradientBoosting_ f1 score-micro-: ', gb_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier_ f1 score-macro-:  0.6556091307849957\n",
      "BaggingClassifier_ f1 score-micro-:  0.9809102015882712\n"
     ]
    }
   ],
   "source": [
    "bc_score, bc_conf_matrix, bc_f1_score_macro, bc_f1_score_micro = run_BaggingClassifier_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(bc_conf_matrix, title='BaggingClassifier_')\n",
    "print('BaggingClassifier_ f1 score-macro-: ', bc_f1_score_macro)\n",
    "print('BaggingClassifier_ f1 score-micro-: ', bc_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB_ f1 score-macro-:  0.6986124136766104\n",
      "GaussianNB_ f1 score-micro-:  0.9580788026878436\n"
     ]
    }
   ],
   "source": [
    "nb_score, nb_conf_matrix, nb_f1_score_macro, nb_f1_score_micro = run_GaussianNB_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(nb_conf_matrix, title='GaussianNB_')\n",
    "print('GaussianNB_ f1 score-macro-: ', nb_f1_score_macro)\n",
    "print('GaussianNB_ f1 score-micro-: ', nb_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVMClassifier_ f1 score-macro-:  0.6687152136123921\n",
      "SVMClassifier_ f1 score-micro-:  0.9816737935247404\n"
     ]
    }
   ],
   "source": [
    "svm_score, svm_conf_matrix, svm_f1_score_macro, svm_f1_score_micro = run_SVMClassifier_algorithm_(X_train, X_test, y_train, y_test)\n",
    "plot_confusion_matrix(nb_conf_matrix, title='SVMClassifier_')\n",
    "print('SVMClassifier_ f1 score-macro-: ', svm_f1_score_macro)\n",
    "print('SVMClassifier_ f1 score-micro-: ', svm_f1_score_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REGRESSION\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# BINC CLASSIFICATION\n",
    "\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_data_ = pd.DataFrame(scaler.fit_transform(train_data[feature_names]), index=train_data.index, columns=feature_names)\n",
    "test_data_ = pd.DataFrame(scaler.transform(test_data[feature_names]), index=test_data.index, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['RUL']\n",
    "X_train = train_data_.copy()\n",
    "\n",
    "y_test = test_data['RUL']\n",
    "X_test = test_data_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_LogisticRegression_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LogisticRegression(random_state=42, verbose=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred))  \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_DecisionTree_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = DecisionTreeRegressor(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_RandomForest_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = RandomForestRegressor(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_GradientBoosting_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = GradientBoostingRegressor(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_BaggingRegressor_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = BaggingRegressor(random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_KNeighborsRegressor_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = KNeighborsRegressor()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_SVMRegressor_algorithm_(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    clf = LinearSVR()\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    rmse = sqrt(mean_squared_error(y_test, y_pred)) \n",
    "    r2_score_ = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return rmse, r2_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_LogisticRegression_ rmse:  58.08243896345779\n",
      "_LogisticRegression_ r2_score:  0.03013421936841454\n"
     ]
    }
   ],
   "source": [
    "log_rmse, log_r2_score_ = _run_LogisticRegression_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_LogisticRegression_ rmse: ', log_rmse)\n",
    "print('_LogisticRegression_ r2_score: ', log_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_DecisionTree_ rmse:  68.68230604095379\n",
      "_DecisionTree_ r2_score:  -0.35616235201609747\n"
     ]
    }
   ],
   "source": [
    "dt_rmse, dt_r2_score_ = _run_DecisionTree_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_DecisionTree_ rmse: ', dt_rmse)\n",
    "print('_DecisionTree_ r2_score: ', dt_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_RandomForest_ rmse:  46.36436407688364\n",
      "_RandomForest_ r2_score:  0.3819970301854727\n"
     ]
    }
   ],
   "source": [
    "rf_rmse, rf_r2_score_ = _run_RandomForest_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_RandomForest_ rmse: ', rf_rmse)\n",
    "print('_RandomForest_ r2_score: ', rf_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_GradientBoosting_ rmse:  45.75235307806861\n",
      "_GradientBoosting_ r2_score:  0.39820466439627\n"
     ]
    }
   ],
   "source": [
    "gb_rmse, gb_r2_score_ = _run_GradientBoosting_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_GradientBoosting_ rmse: ', gb_rmse)\n",
    "print('_GradientBoosting_ r2_score: ', gb_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_BaggingRegressor_ rmse:  48.8160272439566\n",
      "_BaggingRegressor_ r2_score:  0.31491128696043746\n"
     ]
    }
   ],
   "source": [
    "br_rmse, br_r2_score_ = _run_BaggingRegressor_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_BaggingRegressor_ rmse: ', br_rmse)\n",
    "print('_BaggingRegressor_ r2_score: ', br_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_KNeighborsRegressor_ rmse:  51.97555381973974\n",
      "_KNeighborsRegressor_ r2_score:  0.22335920653209473\n"
     ]
    }
   ],
   "source": [
    "kn_rmse, kn_r2_score_ = _run_KNeighborsRegressor_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_KNeighborsRegressor_ rmse: ', kn_rmse)\n",
    "print('_KNeighborsRegressor_ r2_score: ', kn_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SVMRegressor_ rmse:  51.243821713678855\n",
      "_SVMRegressor_ r2_score:  0.24507297913396942\n"
     ]
    }
   ],
   "source": [
    "svm_rmse, svm_r2_score_ = _run_SVMRegressor_algorithm_(X_train, X_test, y_train, y_test)\n",
    "print('_SVMRegressor_ rmse: ', svm_rmse)\n",
    "print('_SVMRegressor_ r2_score: ', svm_r2_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
